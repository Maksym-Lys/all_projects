{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85d75f1e",
   "metadata": {},
   "source": [
    "# Dataset preparation\n",
    "\n",
    "This notebook is used to prepare dataset for IMDb sentement analysis\n",
    "from raw reviews. \n",
    "Link on [Kaggel](https://www.kaggle.com/datasets/pawankumargunjan/imdb-review)\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e13aa",
   "metadata": {},
   "source": [
    "Importing libraries and downloading necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba39884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e27ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Maks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Maks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Maks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3195b0",
   "metadata": {},
   "source": [
    "Default train-test split divides the data in half. This results in 25,000 training instances and 25,000 test instances. \n",
    "In order to achieve better results, we can consider using a custom train-test split with our own ratio.\n",
    "For this purpose, I merged all the file paths for training and testing into one source containing 50,000 reviews.\n",
    "\n",
    "Additionally, we have 50,000 unlabeled instances that can be used for unsupervised training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d77fa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of supervised filepaths: 50000\n",
      "Number of unsupervised filepaths: 50000\n"
     ]
    }
   ],
   "source": [
    "filepaths_train_pos = []\n",
    "for dirpath, dirnames, filenames in os.walk(\"D:\\\\Datasets\\\\aclImdb\\\\train\\\\pos\\\\\"):\n",
    "    for file in filenames:\n",
    "        filepaths_train_pos.append(os.path.join(dirpath, file))\n",
    "\n",
    "filepaths_train_neg = []\n",
    "for dirpath, dirnames, filenames in os.walk(\"D:\\\\Datasets\\\\aclImdb\\\\train\\\\neg\\\\\"):\n",
    "    for file in filenames:\n",
    "        filepaths_train_neg.append(os.path.join(dirpath, file))\n",
    "    \n",
    "filepaths_test_pos = []\n",
    "for dirpath, dirnames, filenames in os.walk(\"D:\\\\Datasets\\\\aclImdb\\\\test\\\\pos\\\\\"):\n",
    "    for file in filenames:\n",
    "        filepaths_test_pos.append(os.path.join(dirpath, file))\n",
    "\n",
    "filepaths_test_neg = []\n",
    "for dirpath, dirnames, filenames in os.walk(\"D:\\\\Datasets\\\\aclImdb\\\\test\\\\neg\\\\\"):\n",
    "    for file in filenames:\n",
    "        filepaths_test_neg.append(os.path.join(dirpath, file))\n",
    "        \n",
    "sup_filepaths = []\n",
    "sup_filepaths.extend(filepaths_train_pos)\n",
    "sup_filepaths.extend(filepaths_train_neg)\n",
    "sup_filepaths.extend(filepaths_test_pos)\n",
    "sup_filepaths.extend(filepaths_test_neg)\n",
    "\n",
    "print(f\"Number of supervised filepaths: {len(sup_filepaths)}\")\n",
    "\n",
    "unsup_filepaths = []\n",
    "for dirpath, dirnames, filenames in os.walk(\"D:\\\\Datasets\\\\aclImdb\\\\train\\\\unsup\\\\\"):\n",
    "    for file in filenames:\n",
    "        unsup_filepaths.append(os.path.join(dirpath, file))\n",
    "        \n",
    "print(f\"Number of unsupervised filepaths: {len(unsup_filepaths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ea4e0",
   "metadata": {},
   "source": [
    "Extracting reviews and labels from txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d7897d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb41968e490846a38ef93ecb577b2121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 30.5 s\n",
      "Wall time: 6min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sup_text = []\n",
    "labels = []\n",
    "for filepath in tqdm(sup_filepaths):\n",
    "    with open(filepath, 'r') as file:\n",
    "        sup_text.append(file.read())       \n",
    "        labels.append(os.path.basename(os.path.dirname(filepath)))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a919a2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae15304b52e412ea0f900026fb57ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 27.8 s\n",
      "Wall time: 5min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unsup_text = []\n",
    "for filepath in tqdm(unsup_filepaths):\n",
    "    with open(filepath, 'r') as file:\n",
    "        unsup_text.append(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c0c873",
   "metadata": {},
   "source": [
    "Creating a Pandas dataframe with review text and corresponding labels for supervised data, and another dataframe with review text for unsupervised data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b53d7e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervised_text = pd.DataFrame({\"review_text\":sup_text, \"label\":labels})\n",
    "\n",
    "df_unsupervised_text = pd.DataFrame({\"review_text\":unsup_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6fdf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text label\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...   pos\n",
       "1  Homelessness (or Houselessness as George Carli...   pos\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...   pos\n",
       "3  This is easily the most underrated film inn th...   pos\n",
       "4  This is not the typical Mel Brooks film. It wa...   pos"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_supervised_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ee09509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I admit, the great majority of films released ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Take a low budget, inexperienced actors doubli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everybody has seen 'Back To The Future,' right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doris Day was an icon of beauty in singing and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After a series of silly, fun-loving movies, 19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text\n",
       "0  I admit, the great majority of films released ...\n",
       "1  Take a low budget, inexperienced actors doubli...\n",
       "2  Everybody has seen 'Back To The Future,' right...\n",
       "3  Doris Day was an icon of beauty in singing and...\n",
       "4  After a series of silly, fun-loving movies, 19..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unsupervised_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4b7e64",
   "metadata": {},
   "source": [
    "We can consider reducing the length of tokens by applying 'stop words'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "947b4ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d374e",
   "metadata": {},
   "source": [
    "As we can see, 'stop words' is a list of common words. However, in the case of a sentiment classification task, we may reasonably exclude certain words from this list, such as: 'are', 'aren't', 'did', 'didn't', 'does', 'doesn't'. If we remove these words, we can achieve a completely different meaning in sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f148e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'m', 'am', \"'m\", 'o', 'her', \"you're\", 'a', 'own', 'about', 'why', 'their', 'hers', 'him', 'where', 'now', 'here', 'yours', 'd', \"that'll\", \"'ll\", 'each', 'ourselves', \"you'll\", 'some', 'these', 'down', 'to', 'them', 'whom', 'or', 'between', 'are', 'as', 'herself', 'itself', 'both', 'because', 'same', 'most', 'and', 'they', 'myself', 'been', 'by', 'only', 'having', 'me', 'off', 'be', 'for', 'while', 'yourselves', 'into', 'himself', 'y', \"'s\", 'doing', 'i', 'of', 'other', 'can', 'it', \"it's\", 'yourself', 'theirs', 'up', 'at', 'so', 're', 'this', 'in', 'ours', 'that', 'how', 'with', 'below', 'few', \"should've\", 'until', 'our', 'when', 'after', \"you'd\", 'out', 'during', 'under', 'an', 'there', 'above', 'more', 'what', 'through', 'the', 'your', 'she', 'my', 'who', 'then', 'those', \"she's\", 'from', 'which', 'than', 'you', 'once', 'again', 'any', 'his', 'further', 'll', 'over', 'all', 'its', 'if', \"'ve\", 'themselves', \"you've\", 'we', 'he', 'such', 've', 'before', 'on', 'being', 'just', 'but'}\n"
     ]
    }
   ],
   "source": [
    "custom_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "custom_stopwords -= set([\n",
    "    'are', 'aren', \"aren't\", \n",
    "    'could', 'couldn', \"couldn't\", \n",
    "    'did', 'didn', \"didn't\", \n",
    "    'does', 'doesn', \"doesn't\", \n",
    "    'had', 'hadn', \"hadn't\", \n",
    "    'has', 'hasn', \"hasn't\", \n",
    "    'have', 'haven', \"haven't\", \n",
    "    'is', 'isn', \"isn't\", \n",
    "    'might', 'ma', 'mightn', \"mightn't\", \n",
    "    'must', 'mustn', \"mustn't\", \n",
    "    'need', 'needn', \"needn't\", \n",
    "    'shall', 'shan', \"shan't\", \n",
    "    'should', 'shouldn', \"shouldn't\", \n",
    "    'was', 'wasn', \"wasn't\", \n",
    "    'were', 'weren', \"weren't\", \n",
    "    'will', 'won', \"won't\", \n",
    "    'would', 'wouldn', \"wouldn't\", \n",
    "    'do', 'don', \"don't\", \n",
    "    't', 's',\n",
    "    \n",
    "    'too', 'very', 'should', 'no', 'not', 'against', 'nor', 'ain',\n",
    "])\n",
    "\n",
    "custom_stopwords.update([\n",
    "    \"'s\", \"'ve\", \"'ll\", \"'m\"\n",
    "])\n",
    "\n",
    "print(custom_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f38e46",
   "metadata": {},
   "source": [
    "We will create functions for text preprocessing and extracting the length of the tokens. The raw data contains HTML syntax, so we can use the bs4 library for text cleaning. Next, we'll preprocess the text using the re library, convert it to lowercase, remove words according to the 'stop words' list, and lemmatize sentences. Lemmatization can reduce the diversity of sentences that are similar in context but differ in syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4bdfa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text_fn(x):\n",
    "   \n",
    "    x = BeautifulSoup(x, 'html.parser').get_text()\n",
    "    \n",
    "    x = re.sub(r\"[;:]\", '.', x)\n",
    "    x = re.sub(r\"[^a-zA-Z0-9'!?.,;: ]\", '', x)\n",
    "    x = re.sub(r'\\.', ' . ', x)\n",
    "    x = re.sub(r'\\s+', ' ', x)\n",
    "\n",
    "    x = x.lower()\n",
    "\n",
    "    words = nltk.word_tokenize(x)\n",
    "\n",
    "    words = [word for word in words if word not in custom_stopwords]\n",
    "    \n",
    "    words = [lemmatizer.lemmatize(word, \"v\") for word in words]\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    x = ' '.join(words)   \n",
    "    return x\n",
    "\n",
    "def get_length(x):\n",
    "    return len(x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027d193",
   "metadata": {},
   "source": [
    "In this cell we can see work of cleaning function on random review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9abf03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can any movie become more naive than this? you cant believe a piece of this script. and its ssooooo predictable that you can tell the plot and the ending from the first 10 minutes. the leading actress seems like she wants to be Barbie (but she doesn't make it, the doll has MORE acting skills).<br /><br />the easiness that the character passes and remains in a a music school makes the phantom of the opera novel seem like a historical biography. i wont even comment on the shallowness of the characters but the ONE good thing of the film is Madsen's performance which manages to bring life to a melo-like one-dimensional character.<br /><br />The movie is so cheesy that it sticks to your teeth. i can think some 13 year old Britney-obsessed girls shouting \"O, do give us a break! If we want fairy tales there is always the Brothers Grimm book hidden somewhere in the attic\". I gave it 2 instead of one only for Virginia Madsen.\n",
      "\n",
      "\n",
      "movie become naive ? cant believe piece script . ssooooo predictable tell plot end first 10 minute . lead actress seem like want barbie do n't make , doll have act skill . easiness character pas remain music school make phantom opera novel seem like historical biography . wont even comment shallowness character one good thing film be madsen performance manage bring life melolike onedimensional character . movie be cheesy stick teeth . think 13 year old britneyobsessed girl shout , do give u break ! want fairy tale be always brother grimm book hide somewhere attic . give 2 instead one virginia madsen .\n",
      "\n",
      "\n",
      "The length of raw review:        168\n",
      "The length of cleaned review:    105\n"
     ]
    }
   ],
   "source": [
    "test_text = random.choice(df_supervised_text[\"review_text\"].values)\n",
    "print(test_text)\n",
    "print(\"\\n\")\n",
    "print(clean_text_fn(test_text))\n",
    "print(\"\\n\")\n",
    "print(f\"The length of raw review:        {len(test_text.split())}\")\n",
    "print(f\"The length of cleaned review:    {len(clean_text_fn(test_text).split())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2658e4",
   "metadata": {},
   "source": [
    "Adding the cleaned text and the length of tokens to corresponding pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4591cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maks\\AppData\\Local\\Temp\\ipykernel_9960\\1866251050.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  x = BeautifulSoup(x, 'html.parser').get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6min 1s\n",
      "Wall time: 6min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_supervised_text[\"cleaned_review_text\"] = df_supervised_text[\"review_text\"].apply(lambda x: clean_text_fn(x))\n",
    "df_supervised_text[\"number_of_tokens\"] = df_supervised_text[\"cleaned_review_text\"].apply(lambda x: get_length(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f508a8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maks\\AppData\\Local\\Temp\\ipykernel_9960\\1866251050.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  x = BeautifulSoup(x, 'html.parser').get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6min 11s\n",
      "Wall time: 6min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_unsupervised_text[\"cleaned_review_text\"] = df_unsupervised_text[\"review_text\"].apply(lambda x: clean_text_fn(x))\n",
    "df_unsupervised_text[\"number_of_tokens\"] = df_unsupervised_text[\"cleaned_review_text\"].apply(lambda x: get_length(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dface85",
   "metadata": {},
   "source": [
    "prepared supervised dataframe contains raw reviews, labels, cleaned reviews, and the length of cleaned reviews. The prepared unsupervised dataframe has the same columns except for labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c1579bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "      <th>number_of_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>pos</td>\n",
       "      <td>bromwell high be cartoon comedy . run time pro...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>pos</td>\n",
       "      <td>homelessness houselessness george carlin state...</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>pos</td>\n",
       "      <td>brilliant overact lesley ann warren . best dra...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>pos</td>\n",
       "      <td>be easily underrate film inn brook cannon . su...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>pos</td>\n",
       "      <td>be not typical mel brook film . be much le sla...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text label  \\\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...   pos   \n",
       "1  Homelessness (or Houselessness as George Carli...   pos   \n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...   pos   \n",
       "3  This is easily the most underrated film inn th...   pos   \n",
       "4  This is not the typical Mel Brooks film. It wa...   pos   \n",
       "\n",
       "                                 cleaned_review_text  number_of_tokens  \n",
       "0  bromwell high be cartoon comedy . run time pro...               113  \n",
       "1  homelessness houselessness george carlin state...               263  \n",
       "2  brilliant overact lesley ann warren . best dra...               110  \n",
       "3  be easily underrate film inn brook cannon . su...                90  \n",
       "4  be not typical mel brook film . be much le sla...                81  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_supervised_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6249028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "      <th>number_of_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I admit, the great majority of films released ...</td>\n",
       "      <td>admit , great majority film release say 1933 n...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Take a low budget, inexperienced actors doubli...</td>\n",
       "      <td>take low budget , inexperienced actor double p...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everybody has seen 'Back To The Future,' right...</td>\n",
       "      <td>everybody have see 'back future , ' right ? wh...</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doris Day was an icon of beauty in singing and...</td>\n",
       "      <td>doris day be icon beauty sing act warm voice g...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After a series of silly, fun-loving movies, 19...</td>\n",
       "      <td>series silly , funloving movie , 1955 be big y...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  I admit, the great majority of films released ...   \n",
       "1  Take a low budget, inexperienced actors doubli...   \n",
       "2  Everybody has seen 'Back To The Future,' right...   \n",
       "3  Doris Day was an icon of beauty in singing and...   \n",
       "4  After a series of silly, fun-loving movies, 19...   \n",
       "\n",
       "                                 cleaned_review_text  number_of_tokens  \n",
       "0  admit , great majority film release say 1933 n...               109  \n",
       "1  take low budget , inexperienced actor double p...               113  \n",
       "2  everybody have see 'back future , ' right ? wh...               238  \n",
       "3  doris day be icon beauty sing act warm voice g...                72  \n",
       "4  series silly , funloving movie , 1955 be big y...               144  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unsupervised_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee2ff0e",
   "metadata": {},
   "source": [
    "Creating CSV files that contain the prepared dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42e64e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervised_text.to_csv(\"supervised_with_stop_words.csv\", index=False)\n",
    "df_unsupervised_text.to_csv(\"unsupervised_with_stop_words.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
